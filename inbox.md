# inbox

## code less papers

* [InferLite](http://aclweb.org/anthology/D18-1524)
* [Improving Sentence Representations with Multi-view Frameworks](https://arxiv.org/abs/1810.01064)
* [Efficient Contextual Representation Learning Without Softmax Layer](https://arxiv.org/abs/1902.11269)
* [Cloze-driven Pretraining of Self-attention Networks](https://arxiv.org/abs/1903.07785)
* [Publicly Available Clinical BERT Embeddings](https://arxiv.org/abs/1904.03323): [clinicalBERT](https://github.com/EmilyAlsentzer/clinicalBERT)
* [Unified Language Model Pre-training forNatural Language Understanding and Generation](https://arxiv.org/abs/1905.03197)
* [HIBERT: Document Level Pre-training of Hierarchical BidirectionalTransformers for Document Summarization](https://arxiv.org/abs/1905.06566)
